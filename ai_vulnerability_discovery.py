"""
AI-Powered Vulnerability Discovery Engine
Uses machine learning and heuristics to discover novel attack vectors
"""

import re
import ast
import hashlib
from typing import List, Dict, Set, Tuple, Optional, Any
from dataclasses import dataclass, field
from collections import defaultdict
from enum import Enum


class VulnerabilityPattern(Enum):
    """Known vulnerability patterns"""
    SQL_INJECTION = "sql_injection"
    XSS = "cross_site_scripting"
    COMMAND_INJECTION = "command_injection"
    PATH_TRAVERSAL = "path_traversal"
    XXEINJ = "xxe_injection"
    SSRF = "server_side_request_forgery"
    DESERIALIZATION = "unsafe_deserialization"
    WEAK_CRYPTO = "weak_cryptography"
    HARDCODED_SECRETS = "hardcoded_secrets"
    RACE_CONDITION = "race_condition"
    BUFFER_OVERFLOW = "buffer_overflow"
    INTEGER_OVERFLOW = "integer_overflow"


@dataclass
class CodeVulnerability:
    """Represents a discovered vulnerability in code"""
    pattern: VulnerabilityPattern
    severity: str
    file_path: str
    line_number: int
    code_snippet: str
    explanation: str
    remediation: str
    confidence: float  # 0.0 to 1.0
    context: Dict[str, Any] = field(default_factory=dict)


class StaticAnalysisEngine:
    """Advanced static code analysis for vulnerability discovery"""

    def __init__(self):
        self.vulnerabilities: List[CodeVulnerability] = []

        # Dangerous function patterns
        self.dangerous_patterns = {
            VulnerabilityPattern.SQL_INJECTION: [
                r'execute\s*\([^)]*\+[^)]*\)',  # String concatenation in execute
                r'executemany\s*\([^)]*%[^)]*\)',  # String formatting in SQL
                r'cursor\.execute\s*\([^)]*\.format',  # .format() in SQL
                r'db\.raw\s*\(',  # Raw SQL queries
                r'connection\.execute\s*\([^)]*\+',
            ],
            VulnerabilityPattern.XSS: [
                r'Markup\s*\(',
                r'return\s*.*<.*>',
            ],
            VulnerabilityPattern.COMMAND_INJECTION: [
                r'os\.system\s*\(',
                r'subprocess\.call\s*\([^)]*shell\s*=\s*True',
                r'subprocess\.Popen\s*\([^)]*shell\s*=\s*True',
                r'eval\s*\(',
                r'exec\s*\(',
            ],
            VulnerabilityPattern.PATH_TRAVERSAL: [
                r'open\s*\([^)]*\+',  # String concat in file operations
                r'os\.path\.join\s*\([^)]*\+',
                r'Path\s*\([^)]*\+',
                r'read\s*\([^)]*\.\./',  # Direct .. usage
            ],
            VulnerabilityPattern.DESERIALIZATION: [
                r'pickle\.loads?\s*\(',
                r'yaml\.load\s*\([^)]*\)',  # Without Loader=SafeLoader
                r'marshal\.loads?\s*\(',
                r'jsonpickle\.decode',
            ],
            VulnerabilityPattern.WEAK_CRYPTO: [
                r'hashlib\.md5\s*\(',
                r'hashlib\.sha1\s*\(',
                r'random\.random\s*\(',  # Using random instead of secrets
                r'Cipher\s*\([^)]*MODE_ECB',  # ECB mode
            ],
            VulnerabilityPattern.HARDCODED_SECRETS: [
                r'password\s*=\s*["\'][^"\']+',
                r'api_key\s*=\s*["\'][^"\']+',
                r'secret\s*=\s*["\'][^"\']+',
                r'token\s*=\s*["\'][^"\']+',
                r'app\.config\["SECRET_KEY"\]\s*=\s*".*"',
            ]
        }

        # Dangerous imports
        self.dangerous_imports = {
            'pickle': 'Unsafe deserialization',
            'marshal': 'Unsafe deserialization',
            'yaml': 'Potentially unsafe if not using SafeLoader',
            'eval': 'Code execution risk',
            'exec': 'Code execution risk'
        }

    def analyze_code(self, code: str, file_path: str = "unknown") -> List[CodeVulnerability]:
        """Analyze code for vulnerabilities"""
        lines = code.split('\n')

        # Pattern-based detection
        for pattern_type, patterns in self.dangerous_patterns.items():
            for pattern in patterns:
                for line_num, line in enumerate(lines, 1):
                    if re.search(pattern, line):
                        vuln = CodeVulnerability(
                            pattern=pattern_type,
                            severity=self._get_severity(pattern_type),
                            file_path=file_path,
                            line_number=line_num,
                            code_snippet=line.strip(),
                            explanation=self._get_explanation(pattern_type),
                            remediation=self._get_remediation(pattern_type),
                            confidence=0.8,
                            context={'matched_pattern': pattern}
                        )
                        self.vulnerabilities.append(vuln)

        # AST-based analysis (more sophisticated)
        try:
            tree = ast.parse(code)
            self._analyze_ast(tree, file_path, lines)
        except SyntaxError:
            pass

        return self.vulnerabilities

    def _analyze_ast(self, tree: ast.AST, file_path: str, lines: List[str]):
        """Analyze Abstract Syntax Tree for deeper insights"""

        class VulnerabilityVisitor(ast.NodeVisitor):
            def __init__(self, parent):
                self.parent = parent
                self.lines = lines
                self.file_path = file_path
                self.fstring_tainted_vars = set()

            def visit_Assign(self, node):
                # Check if we are assigning an f-string to a variable
                if isinstance(node.value, ast.JoinedStr):
                    for target in node.targets:
                        if isinstance(target, ast.Name):
                            self.fstring_tainted_vars.add(target.id)

                # Taint variables that come from request objects
                if isinstance(node.value, ast.Call) and isinstance(node.value.func, ast.Attribute):
                    if isinstance(node.value.func.value, ast.Attribute) and node.value.func.value.attr in ('args', 'form', 'json'):
                        for target in node.targets:
                            if isinstance(target, ast.Name):
                                self.fstring_tainted_vars.add(target.id)

                self.generic_visit(node)

            def visit_Call(self, node):
                """Analyze function calls"""
                # Check for dangerous function calls
                if isinstance(node.func, ast.Name):
                    func_name = node.func.id

                    # Check eval/exec with user input
                    if func_name in ['eval', 'exec']:
                        self.parent.vulnerabilities.append(CodeVulnerability(
                            pattern=VulnerabilityPattern.COMMAND_INJECTION,
                            severity="critical",
                            file_path=self.file_path,
                            line_number=node.lineno,
                            code_snippet=self.lines[node.lineno - 1].strip() if node.lineno <= len(self.lines) else "",
                            explanation=f"Use of dangerous {func_name}() function",
                            remediation=f"Avoid using {func_name}(). Use safer alternatives.",
                            confidence=0.95
                        ))

                # Check for SQL with string formatting
                elif isinstance(node.func, ast.Attribute):
                    if node.func.attr == 'execute':
                        # Check if arguments use concatenation, f-strings, or tainted variables
                        for arg in node.args:
                            is_vulnerable = False
                            explanation = ""
                            if isinstance(arg, ast.BinOp) and isinstance(arg.op, ast.Add):
                                is_vulnerable = True
                                explanation = "SQL query uses string concatenation"
                            elif isinstance(arg, ast.JoinedStr):
                                is_vulnerable = True
                                explanation = "SQL query uses f-string formatting directly in execute call"
                            elif isinstance(arg, ast.Name) and arg.id in self.fstring_tainted_vars:
                                is_vulnerable = True
                                explanation = "SQL query uses a variable tainted by an f-string"

                            if is_vulnerable:
                                self.parent.vulnerabilities.append(CodeVulnerability(
                                    pattern=VulnerabilityPattern.SQL_INJECTION,
                                    severity="critical",
                                    file_path=self.file_path,
                                    line_number=node.lineno,
                                    code_snippet=self.lines[node.lineno - 1].strip() if node.lineno <= len(self.lines) else "",
                                    explanation=explanation,
                                    remediation="Use parameterized queries instead",
                                    confidence=0.95
                                ))

                self.generic_visit(node)

            def visit_Import(self, node):
                """Check for dangerous imports"""
                for alias in node.names:
                    if alias.name in self.parent.dangerous_imports:
                        self.parent.vulnerabilities.append(CodeVulnerability(
                            pattern=VulnerabilityPattern.DESERIALIZATION,
                            severity="medium",
                            file_path=self.file_path,
                            line_number=node.lineno,
                            code_snippet=self.lines[node.lineno - 1].strip() if node.lineno <= len(self.lines) else "",
                            explanation=self.parent.dangerous_imports[alias.name],
                            remediation="Use safer alternatives",
                            confidence=0.7
                        ))
                self.generic_visit(node)

            def visit_Return(self, node):
                """Check for tainted data being returned"""
                if isinstance(node.value, ast.Name) and node.value.id in self.fstring_tainted_vars:
                    self.parent.vulnerabilities.append(CodeVulnerability(
                        pattern=VulnerabilityPattern.XSS,
                        severity="high",
                        file_path=self.file_path,
                        line_number=node.lineno,
                        code_snippet=self.lines[node.lineno - 1].strip() if node.lineno <= len(self.lines) else "",
                        explanation="Potential XSS: Tainted data from request is returned without sanitization",
                        remediation="Use a templating engine like Jinja2 with auto-escaping, or explicitly sanitize user input with a library like Bleach.",
                        confidence=0.85,
                    ))
                self.generic_visit(node)

        visitor = VulnerabilityVisitor(self)
        visitor.visit(tree)

    def _get_severity(self, pattern: VulnerabilityPattern) -> str:
        """Get severity level for pattern"""
        critical_patterns = [
            VulnerabilityPattern.SQL_INJECTION,
            VulnerabilityPattern.COMMAND_INJECTION,
            VulnerabilityPattern.DESERIALIZATION
        ]

        if pattern in critical_patterns:
            return "critical"
        elif pattern in [VulnerabilityPattern.XSS, VulnerabilityPattern.SSRF]:
            return "high"
        elif pattern in [VulnerabilityPattern.WEAK_CRYPTO, VulnerabilityPattern.PATH_TRAVERSAL]:
            return "medium"
        else:
            return "low"

    def _get_explanation(self, pattern: VulnerabilityPattern) -> str:
        """Get explanation for vulnerability pattern"""
        explanations = {
            VulnerabilityPattern.SQL_INJECTION:
                "SQL injection allows attackers to manipulate database queries",
            VulnerabilityPattern.COMMAND_INJECTION:
                "Command injection enables arbitrary system command execution",
            VulnerabilityPattern.PATH_TRAVERSAL:
                "Path traversal allows access to files outside intended directory",
            VulnerabilityPattern.DESERIALIZATION:
                "Unsafe deserialization can lead to remote code execution",
            VulnerabilityPattern.WEAK_CRYPTO:
                "Weak cryptographic algorithms are vulnerable to attacks",
            VulnerabilityPattern.HARDCODED_SECRETS:
                "Hardcoded secrets can be extracted from source code"
        }
        return explanations.get(pattern, "Security vulnerability detected")

    def _get_remediation(self, pattern: VulnerabilityPattern) -> str:
        """Get remediation advice"""
        remediations = {
            VulnerabilityPattern.SQL_INJECTION:
                "Use parameterized queries or ORM. Never concatenate user input into SQL.",
            VulnerabilityPattern.COMMAND_INJECTION:
                "Avoid shell=True. Use subprocess with argument lists. Validate input.",
            VulnerabilityPattern.PATH_TRAVERSAL:
                "Validate and sanitize file paths. Use os.path.abspath() and check prefix.",
            VulnerabilityPattern.DESERIALIZATION:
                "Use JSON instead of pickle. If pickle is necessary, sign/verify data.",
            VulnerabilityPattern.WEAK_CRYPTO:
                "Use SHA-256 or better. Use secrets module for random values.",
            VulnerabilityPattern.HARDCODED_SECRETS:
                "Use environment variables or secrets management systems."
        }
        return remediations.get(pattern, "Follow security best practices")


class DataFlowAnalyzer:
    """Analyze data flow to detect taint propagation"""

    def __init__(self):
        self.tainted_sources = [
            'request.', 'input(', 'sys.argv', 'os.environ',
            'request.GET', 'request.POST', 'request.json'
        ]

        self.dangerous_sinks = [
            'execute(', 'system(', 'eval(', 'exec(',
            'open(', 'write(', 'send('
        ]

    def trace_data_flow(self, code: str) -> List[Dict]:
        """Trace data from sources to sinks"""
        flows = []
        lines = code.split('\n')

        # Simple taint analysis
        tainted_vars = set()

        for line_num, line in enumerate(lines, 1):
            # Check if line taints a variable
            for source in self.tainted_sources:
                if source in line:
                    # Extract variable name
                    match = re.search(r'(\w+)\s*=.*' + re.escape(source), line)
                    if match:
                        var_name = match.group(1)
                        tainted_vars.add(var_name)

            # Check if tainted variable reaches sink
            for var in tainted_vars:
                for sink in self.dangerous_sinks:
                    if var in line and sink in line:
                        flows.append({
                            'source_var': var,
                            'sink': sink,
                            'line': line_num,
                            'code': line.strip(),
                            'risk': 'high'
                        })

        return flows


class BehavioralAnalyzer:
    """Analyze code behavior patterns"""

    def __init__(self):
        self.suspicious_patterns = []

    def analyze_loops(self, code: str) -> List[Dict]:
        """Detect potentially infinite loops or resource exhaustion"""
        issues = []

        try:
            tree = ast.parse(code)

            for node in ast.walk(tree):
                if isinstance(node, (ast.For, ast.While)):
                    # Check for unbounded loops
                    if isinstance(node, ast.While):
                        if isinstance(node.test, ast.Constant) and node.test.value is True:
                            issues.append({
                                'type': 'infinite_loop',
                                'line': node.lineno,
                                'risk': 'high',
                                'description': 'Potentially infinite while True loop'
                            })
        except SyntaxError:
            pass

        return issues

    def analyze_recursion(self, code: str) -> List[Dict]:
        """Detect unbounded recursion"""
        issues = []

        try:
            tree = ast.parse(code)

            class RecursionVisitor(ast.NodeVisitor):
                def __init__(self):
                    self.functions = {}
                    self.recursive_funcs = []

                def visit_FunctionDef(self, node):
                    func_name = node.name
                    self.functions[func_name] = node

                    # Check if function calls itself
                    for child in ast.walk(node):
                        if isinstance(child, ast.Call):
                            if isinstance(child.func, ast.Name) and child.func.id == func_name:
                                # Found recursion - check for base case
                                has_base_case = any(
                                    isinstance(n, ast.Return)
                                    for n in ast.walk(node)
                                )

                                if not has_base_case:
                                    self.recursive_funcs.append({
                                        'function': func_name,
                                        'line': node.lineno,
                                        'risk': 'critical'
                                    })

                    self.generic_visit(node)

            visitor = RecursionVisitor()
            visitor.visit(tree)
            issues.extend(visitor.recursive_funcs)

        except SyntaxError:
            pass

        return issues


class AIVulnerabilityDiscovery:
    """
    Master AI-powered vulnerability discovery engine
    Combines multiple analysis techniques
    """

    def __init__(self):
        self.static_analyzer = StaticAnalysisEngine()
        self.dataflow_analyzer = DataFlowAnalyzer()
        self.behavioral_analyzer = BehavioralAnalyzer()

        self.all_vulnerabilities = []
        self.statistics = defaultdict(int)

    def discover_vulnerabilities(self,
                                 code: str,
                                 file_path: str = "unknown") -> Dict[str, Any]:
        """
        Comprehensive vulnerability discovery
        """
        results = {
            'file': file_path,
            'static_analysis': [],
            'dataflow_analysis': [],
            'behavioral_analysis': [],
            'risk_score': 0.0,
            'summary': {}
        }

        print(f"[*] Analyzing {file_path}...")

        # Static analysis
        self.static_analyzer.vulnerabilities = []
        static_vulns = self.static_analyzer.analyze_code(code, file_path)
        results['static_analysis'] = [
            {
                'pattern': v.pattern,
                'severity': v.severity,
                'file_path': v.file_path,
                'line_number': v.line_number,
                'code_snippet': v.code_snippet,
                'explanation': v.explanation,
                'remediation': v.remediation,
                'confidence': v.confidence
            }
            for v in static_vulns
        ]

        # Data flow analysis
        dataflows = self.dataflow_analyzer.trace_data_flow(code)
        results['dataflow_analysis'] = dataflows

        # Behavioral analysis
        loop_issues = self.behavioral_analyzer.analyze_loops(code)
        recursion_issues = self.behavioral_analyzer.analyze_recursion(code)
        results['behavioral_analysis'] = loop_issues + recursion_issues

        # Calculate risk score
        risk_score = self._calculate_risk_score(results)
        results['risk_score'] = risk_score

        # Generate summary
        results['summary'] = self._generate_summary(results)

        # Update statistics
        self._update_statistics(results)

        return results

    def _calculate_risk_score(self, results: Dict) -> float:
        """Calculate overall risk score (0-100)"""
        score = 0.0

        # Weight by severity
        severity_weights = {'critical': 10, 'high': 7, 'medium': 4, 'low': 1}

        for vuln in results['static_analysis']:
            weight = severity_weights.get(vuln['severity'], 1)
            confidence = vuln['confidence']
            score += weight * confidence

        for flow in results['dataflow_analysis']:
            score += 5.0  # Tainted data flows are serious

        for issue in results['behavioral_analysis']:
            if issue.get('risk') == 'critical':
                score += 8.0
            elif issue.get('risk') == 'high':
                score += 5.0

        # Normalize to 0-100
        return min(100.0, score)

    def _generate_summary(self, results: Dict) -> Dict:
        """Generate summary statistics"""
        summary = {
            'total_vulnerabilities': len(results['static_analysis']),
            'critical': 0,
            'high': 0,
            'medium': 0,
            'low': 0,
            'tainted_flows': len(results['dataflow_analysis']),
            'behavioral_issues': len(results['behavioral_analysis'])
        }

        for vuln in results['static_analysis']:
            sev = vuln['severity']
            if sev in summary:
                summary[sev] += 1

        return summary

    def _update_statistics(self, results: Dict):
        """Update global statistics"""
        for vuln in results['static_analysis']:
            self.statistics[vuln['pattern'].value] += 1
            self.statistics[f"severity_{vuln['severity']}"] += 1

        self.statistics['total_files_analyzed'] += 1

    def generate_comprehensive_report(self) -> str:
        """Generate comprehensive analysis report"""
        report = []
        report.append("=" * 80)
        report.append("AI-POWERED VULNERABILITY DISCOVERY REPORT")
        report.append("=" * 80)

        report.append(f"\nTotal Files Analyzed: {self.statistics['total_files_analyzed']}")

        return "\n".join(report)
